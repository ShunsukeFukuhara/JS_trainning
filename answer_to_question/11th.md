演習17.2でPolly.jsを初めて知ったのですが、JS/TSのテストとして使う機会は多いのでしょうか？
最初の1回だけAPIと通信し、その結果を使いたいケースがどんなときなのかよくわかりませんでした。
最初の1回のAPIの結果がある状態(ほしい結果が明らか)なのであれば、Jestのmockでその結果を固定してテストすればよいのではないかと思いました。

Polly.jsは、APIとの通信を記録して再生するためのライブラリです。これにより、最初の1回だけAPIと通信し、その結果を保存しておくことができます。次回以降のテストでは、その保存された結果を再生することで、APIとの通信を行わずにテストを実行できます。
このようなケースは、APIのレスポンスが頻繁に変わる場合や、APIのレスポンスが大きくてテストの実行時間が長くなる場合などに有効です。Jestのmockを使用することもできますが、Polly.jsはより柔軟で強力な機能を提供しており、APIとの通信をよりリアルにシミュレートすることができます。
例えば、APIのレスポンスが頻繁に変わる場合、Jestのmockでは毎回レスポンスを更新する必要がありますが、Polly.jsを使用すれば、最初の1回だけAPIと通信して結果を保存し、その後はその結果を再生するだけで済みます。また、APIのレスポンスが大きい場合、Jestのmockではレスポンスを手動で作成する必要がありますが、Polly.jsは実際のAPIとの通信を記録するため、レスポンスの内容を正確に再現できます。
したがって、APIとの通信を行うテストにおいて、Polly.jsは非常に便利なツールとなります。特に、APIのレスポンスが頻繁に変わる場合や、レスポンスが大きい場合には、Polly.jsを使用することでテストの効率を大幅に向上させることができます。

正直面倒だと思った。REST APIくらいのシンプルな通信であれば、Jestのmockで十分だと思う。

Polly.jsってNetflixが作ったんだ。

https://www.infoq.com/news/2018/07/netflix-pollyjs-http-library/

Netflixチームは、フィクスチャとファクトリをAPIと同等に保つことが難しいことに気づき＞分かる。

Netflix 当時は：

JS中心

型保証弱い

REST主体

後方互換性重視

だったため、

「実レスポンス録画」＝事実上の契約

として機能しました。

今は：

TypeScript前提

GraphQLスキーマ駆動

Codegen文化

なので、録画だけでは不十分に見えるのは自然です

ただ、Polly.jsはAPIとの通信を記録して再生するためのツールであり、APIのレスポンスが頻繁に変わる場合や、レスポンスが大きい場合には非常に便利です。Jestのmockも十分な場合がありますが、Polly.jsはより柔軟で強力な機能を提供しているため、特定のケースではより適していると言えます。

モックを作成するコストが、一定以上の複雑さを持つAPIに対しては、Polly.jsの方が効率的である可能性があります。特に、APIのレスポンスが頻繁に変わる場合や、レスポンスが大きい場合には、Polly.jsを使用することでテストの効率を大幅に向上させることができます。

アプリやゲーム、Webサイト上で、そのサービスが利用しているライブラリのライセンスが公開されているのを目にします。
これは、ユーザーに配布されるライブラリ(package.jsonでのdependenciesに含まれるもの)が対象という認識なのですが、そのライブラリが更に依存しているライブラリも表示の対象になるのでしょうか？
もし対象になる場合、表示対象が膨大になるためlicense-checkerなどのツールを使わざる得ないと思うのですが、ツールで自動化すると正確性が保証できなくなると思います。どのようにして正確性を確保するのが一般的なのでしょうか？
ー＞はい。そうです。OSS診断でも、フロントエンドの癖に申告されているOSSが少なければ指導します。
通常、ツールを使用します。

「合理的な管理プロセスがあること」が重要

法律的にも：

故意でない

管理体制がある

修正対応できる

なら問題になりにくい。

「eslintスクリプトが./node_modules/.bin/eslintに入ってしまい、コマンドを実行するのが面倒になります」の部分で、面倒な実行方法がどんな方法を指すのかがわかりませんでした（重要そうな部分だけど）。

コマンドで実行する場合は、フルパスを書かないといけないから面倒かも。

npm audit は脆弱性情報を npm 公式の脆弱性データベースから取得しているらしいが、CVE との情報反映ラグなどもあると思うので、完璧に脆弱性を修正できるわけではないと考えておいた方がよいのでしょうか？
また、npm audit fix は GitHub の CI に含めたほうがよいですか？
-> fixしたら壊れるので、CIに含めるのは避けた方がいいと思います。npm auditは脆弱性情報を提供するツールですが、完璧ではありません。CVEとの情報反映ラグや、特定の脆弱性がまだデータベースに登録されていない場合もあります。そのため、npm auditを使用して脆弱性を修正する際には、常に注意が必要です。

さらに、他のプロジェクトではパッケージの依存関係のチェックと更新をどのように行っているのか、特に自動化している例があれば教えてほしいです。（前のプロジェクトでdependabotを使用していたがチェックとマージは手動で面倒だったので。）
多くのプロジェクトでは、DependabotやRenovateなどのツールを使用して、依存関係の更新を自動化しています。これらのツールは、定期的に依存関係をチェックし、更新が必要な場合には自動的にプルリクエストを作成します。ただし、これらのプルリクエストは手動でレビューしてマージする必要があります。完全に自動化することは難しいですが、これらのツールを使用することで、依存関係の管理が大幅に効率化されます。

ESLintをnpmでインストールすると./node_modules/.bin/eslint に入るため ./node_modules/.bin/eslint ファイル名で実行するようにする必要があると記載されていたと思います。
この面倒な実行方法が実際にどのような状況を指しているのかがいまいち理解できませんでした。
npm scriptsを使えばnpm run lintのように簡単に実行できると思うのですが、この部分の説明は「nom scriptsを使わずに直接実行した場合の話」で合っていますか？

はい、その通りです。npm scriptsを使用すれば、package.jsonのscriptsセクションにコマンドを定義することで、簡単に実行できます。しかし、npm scriptsを使用せずに直接コマンドを実行する場合は、./node_modules/.bin/eslintのフルパスを指定する必要があります。これが面倒な実行方法とされる理由です。npm scriptsを使用することで、この問題を回避できます。

yarn は npm よりも速いくらいの認識で何が違うのかいまいちわかっていません。pnpm に関しては何もわかっていません。それぞれの特徴は何でしょうか？

Yarnは、Facebookが開発したパッケージマネージャーで、npmよりも高速なインストールを提供することを目的としています。Yarnは、依存関係の解決やキャッシュ機能などの改善により、npmよりも効率的なパッケージ管理を実現しています。
pnpmは、Yarnやnpmとは異なるアプローチを採用しているパッケージマネージャーです。pnpmは、依存関係を共有することでディスクスペースを節約し、インストール速度を向上させることを目的としています。pnpmは、依存関係をグローバルにインストールし、プロジェクトごとにシンボリックリンクを作成することで、効率的なパッケージ管理を実現しています。

JavaScriptのパッケージ管理ツールはnpm,yarn,pnpmなどその他も含め、どのように選択すると良いのでしょうか？例えば、利用しようとしているリポジトリに存在しているlockファイルで判断するといったことで良いのでしょうか？

パッケージ管理ツールの選択は、プロジェクトの要件やチームの好みによって異なります。一般的には、利用しようとしているリポジトリに存在しているlockファイルを確認することが推奨されます。例えば、package-lock.jsonが存在する場合はnpmが使用されている可能性が高く、yarn.lockが存在する場合はYarnが使用されている可能性が高いです。
ただし、lockファイルが存在しない場合や、複数のlockファイルが存在する場合は、プロジェクトのドキュメントやチームのメンバーに確認することが重要です。また、プロジェクトの依存関係やビルドプロセスなどの要件も考慮して、最適なパッケージ管理ツールを選択することが推奨されます。
最近yarnとnpmは差が埋まってきていて、別にどちらでも良い、それならNode.jsの公式パッケージマネージャーであるnpmを使うのが無難では？F

逆にnpmは、Node.jsの公式パッケージマネージャーであり、広く使用されているため、互換性やサポートが充実しています。npmは、依存関係の管理やスクリプトの実行などの基本的な機能を提供しており、多くのプロジェクトで使用されています。

ホットモジュール交換について、「この機能がうまく動くようにするには、いくつか仕掛けが必要となり、すべてのプロジェクトに適しているわけではありません」とありますが、必要となる仕掛けはどういったものなのでしょうか？ また、どういったプロジェクトに適していないのでしょうか？

ホットモジュール交換（HMR）を実現するためには、いくつかの仕掛けが必要です。まず、モジュールバンドラー（例：Webpack）を使用して、コードの変更を検知し、変更されたモジュールだけを再読み込みするように設定する必要があります。また、アプリケーションコードもHMRに対応するように設計されている必要があります。例えば、Reactの場合は、React Hot LoaderやFast Refreshなどのツールを使用して、コンポーネントの状態を保持しながら更新できるようにする必要があります。

HMRを実現するための仕掛けは、プロジェクトの構成や使用しているフレームワークによって異なりますが、一般的には以下のようなものが必要です：

1. モジュールバンドラーの設定：HMRをサポートするモジュールバンドラーを使用し、HMRを有効にするための設定が必要です。
2. アプリケーションコードの対応：アプリケーションコードがHMRに対応している必要があります。これには、状態管理やコンポーネントの再レンダリングなどの考慮が必要です。
3. 開発サーバーの設定：HMRを使用するためには、開発サーバーもHMRをサポートするように設定する必要があります。
4. ブラウザの対応：HMRを使用するためには、ブラウザもHMRをサポートする必要があります。
5. エラーハンドリングの実装：HMRは、コードの変更をリアルタイムで反映するため、エラーが発生した場合のハンドリングも重要です。
6. テストの対応：HMRを使用する場合、テストコードもHMRに対応するように設計されている必要があります。
7. ビルドプロセスの調整：HMRを使用するためには、ビルドプロセスもHMRに対応するように調整する必要があります。
8. ドキュメントの整備：HMRを使用するためには、プロジェクトのドキュメントもHMRに対応するように整備する必要があります。

- モジュール単位で分割されたコード
- 依存グラフを管理するビルド／ローダー
- 実行中コードを差し替えるランタイム
- 差し替えを受け入れる仕組み（accept機構）
- 状態保持と再描画の仕組み

これを個別の実装で適用するのは難しいから、フレームワークがHMRをサポートしていることが重要になります。

HMRが適していないプロジェクトは、主に以下のようなものです：

1. 大規模なプロジェクト：HMRは、変更されたモジュールだけを再読み込みするため、非常に大規模なプロジェクトでは、変更の検知や再読み込みのパフォーマンスが低下する可能性があります。
2. レガシーコードベース：既存のコードベースがHMRに対応していない場合、HMRを導入するためのリファクタリングが必要になることがあり、そのコストが高い場合には適していないと判断されることがあります。
3. 特定のフレームワークやライブラリを使用していないプロジェクト：HMRは、特定のフレームワークやライブラリ（例：React、Vue.jsなど）で特に効果的ですが、これらを使用していないプロジェクトでは、HMRのメリットが少ない場合があります。

変換後のコードが「読みやすく、理解しやすい」とありますが、個人的にはJSXの方がHTML構造として読みやすいと感じました。
ここでいう「読みやすさ」は可読性ではなく、内部構造の見えやすさを指しているのでしょうか。
また、Reactはなぜ最初から関数呼び出し形式ではなく、JSXという糖衣構文を採用したのでしょうか。
中かっこで閉じたJSX内のJavaScriptがどのように作用されているのかは変換後のコードの方が理解しやすい、ということなだけで特にこの説明が関数呼び出し形式の方が読みやすいということではない
Reactが最初から関数呼び出し形式ではなく、JSXという糖衣構文を採用した理由は、JSXがHTMLのような構造を持っているため、UIの構造を直感的に表現できるからです。JSXは、JavaScriptの中にHTMLのような構造を埋め込むことができるため、UIの構造を視覚的に把握しやすくなります。また、JSXは、Reactコンポーネントの宣言的なスタイルと相性が良く、コードの可読性を向上させることができます。

JS自体がUIを構築するための言語ではないから、がシンプルな理由になる。
